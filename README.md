# ğŸ“Š Insurance Claims Prediction â€” Machine Learning Project ğŸš—ğŸ¤–

## ğŸ§  Project Overview

This project presents a complete end-to-end Machine Learning pipeline to predict whether a customer will file an **insurance claim** based on vehicle, customer, and policy features. It demonstrates a full Business Intelligence & AI workflow including data cleaning, feature engineering, preprocessing pipelines, class imbalance handling, and ensemble modeling.

The system was designed to be **production-ready**, with reusable preprocessing pipelines and saved model artifacts.

---

## ğŸ¯ Problem Statement

Insurance companies need accurate claim prediction to:

* Reduce financial risk ğŸ’°
* Improve pricing strategies ğŸ“ˆ
* Identify high-risk customers early âš ï¸
* Support data-driven underwriting decisions ğŸ¦

**Objective:**
Build a classification model that predicts:

> `claim_status` â†’ whether a policy holder will file a claim or not.

---

## ğŸ—‚ï¸ Dataset Description

The dataset contains structured insurance and vehicle information, including:

* ğŸ‘¤ Customer age
* ğŸš— Vehicle age
* ğŸŒ Region & population density
* ğŸ”§ Engine and power specifications
* â›½ Fuel type
* ğŸ›¡ï¸ Safety features (ESC, airbags, TPMS, etc.)
* âš™ï¸ Transmission & steering type
* ğŸ“¦ Vehicle dimensions and weight
* ğŸ§¾ Policy subscription length

**Target Variable:** Claim Status (Yes / No)

---

## ğŸ” Exploratory Data Analysis (EDA)

Comprehensive EDA was performed to understand data quality and distributions:

* âœ… Missing value analysis
* âœ… Duplicate record checks
* âœ… Statistical summaries
* âœ… Class distribution plots
* âœ… Count plots and pie charts
* âœ… Outlier detection using IQR
* âœ… Boxplots after outlier treatment

Outliers were handled using the **IQR clipping method** to improve model stability.

---

## ğŸ› ï¸ Feature Engineering

Text-based mechanical specifications were transformed into numerical features:

Extracted from:

* `max_torque`
* `max_power`

Created new features:

* torque_nm
* torque_rpm
* power_nm
* power_rpm

This conversion improved model learning by turning text specs into numeric signals ğŸ”¬

---

## âš™ï¸ Data Preprocessing Pipeline

A full preprocessing pipeline was built using **ColumnTransformer + Scikit-Learn Pipelines**.

### ğŸ”¢ Numerical Features

* Median imputation

### ğŸŸ¢ Binary Categorical Features

* Most frequent imputation
* Ordinal encoding

### ğŸŸ¡ Nominal Categorical Features

* One-Hot Encoding

### ğŸ¯ High-Cardinality Features

* Target Encoding for better signal extraction

Pipeline saved for reuse:

```
joblib.dump(preprocessor, "insurance_preprocessor.pkl")
```

---

## âš–ï¸ Handling Class Imbalance

The dataset showed class imbalance in claim labels.

Applied:

* **SMOTE (Synthetic Minority Over-sampling Technique)**

This improves minority class prediction performance and recall ğŸ¯

---

## ğŸ¤– Models Used

An ensemble model using **Soft Voting** was built from three strong learners:

### ğŸŒ² Random Forest

* Robust and noise-resistant
* Multiple decision trees

### ğŸš€ XGBoost

* Gradient boosting algorithm
* Excellent performance on structured data

### ğŸŒ³ HistGradientBoosting

* Fast boosting method
* Efficient with large datasets

---

## ğŸ§© Ensemble Strategy

Used **Weighted Soft Voting**:

```
weights = [2, 2, 3]
```

HistGradientBoosting received slightly higher weight for stronger influence ğŸ†

This improves stability and generalization.

---

## ğŸ§ª Training Setup

* Train/Test Split: 80% / 20%
* Random State: 42
* Full pipeline included:

  * Preprocessing
  * SMOTE balancing
  * Ensemble classifier

Unified pipeline structure:

```
Preprocessor â†’ SMOTE â†’ Voting Classifier
```

---

## ğŸ“ Evaluation Metrics

Models were evaluated using:

* âœ… Accuracy
* âœ… F1 Score
* âœ… ROC-AUC
* âœ… Confusion Matrix

### ğŸ“Š Final Model Performance

Fill with your notebook results:

* Accuracy: **XX%**
* F1 Score: **XX**
* ROC-AUC: **XX**

Confusion matrix visualization used for detailed error analysis ğŸ”

---

## ğŸ“š Libraries & Tools Used

* pandas
* numpy
* matplotlib
* seaborn
* scikit-learn
* imbalanced-learn
* xgboost
* category_encoders
* joblib

---

## ğŸ—ï¸ Project Workflow

```
Raw Data
 â†“
EDA & Cleaning
 â†“
Feature Engineering
 â†“
Preprocessing Pipeline
 â†“
SMOTE Balancing
 â†“
Ensemble Models
 â†“
Evaluation
 â†“
Saved Model & Pipeline
```

---

## ğŸ’¾ Saved Artifacts

* âœ… Preprocessing pipeline file
* âœ… Trained ensemble model
* âœ… Engineered dataset version

Ready for deployment and reuse ğŸš€

---

## ğŸ§  Key Learning Outcomes

* Building advanced preprocessing pipelines ğŸ§©
* Handling imbalanced datasets âš–ï¸
* Feature engineering from text attributes ğŸ”¬
* Ensemble learning strategies ğŸ¤
* Weighted soft voting models ğŸ†
* Production-style ML workflow ğŸ—ï¸

---

**Author:** CS & AI Student â€” Business Intelligence Project
